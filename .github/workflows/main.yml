name: CI

on:
  push:
    branches:
      - main
    paths-ignore:
      - '**/README.md'
  pull_request:
    branches:
      - main
    paths-ignore:
      - '**/README.md'

env:
  IMAGE_NAME: triton-cpu-onnxruntime
  IMAGE_TAG_PREFIX: r25.02

jobs:
  image:
    name: Build Image And Push
    runs-on: ubuntu-latest
    permissions:
      packages: write
      contents: read
    steps:
      - uses: actions/checkout@v2
      - name: Build image
        run: |
          cat /proc/cpuinfo
          wget -c https://github.com/triton-inference-server/server/archive/refs/tags/v2.55.0.zip
          unzip v2.55.0.zip
          cd server-2.55.0
          python build.py --no-container-interactive --no-container-source \
            --image=gpu-base,nvcr.io/nvidia/tritonserver:25.02-py3-min \
            --enable-logging --endpoint=grpc --endpoint=http --repoagent=checksum \
            --repo-tag=common:r25.02 --repo-tag=core:r25.02 --repo-tag=backend:r25.02 --repo-tag=thirdparty:r25.02 \
            --backend=onnxruntime:r25.02 --backend=tensorflow:r25.02 --backend=python:r25.02 --backend=ensemble \
            --override-backend-cmake-arg=onnxruntime:TRITON_ENABLE_GPU=OFF \
            --override-backend-cmake-arg=onnxruntime:TRITON_ENABLE_STATS=OFF \
            --override-backend-cmake-arg=onnxruntime:TRITON_BACKEND_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=onnxruntime:TRITON_CORE_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=onnxruntime:TRITON_COMMON_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=onnxruntime:TRITON_BUILD_ONNXRUNTIME_VERSION=1.20.1 \
            --override-backend-cmake-arg=onnxruntime:TRITON_ENABLE_ONNXRUNTIME_OPENVINO=ON \
            --override-backend-cmake-arg=onnxruntime:TRITON_BUILD_ONNXRUNTIME_OPENVINO_VERSION=2025.0.0 \
            --extra-backend-cmake-arg=onnxruntime:CMAKE_C_FLAGS="-march=core-avx2 -mtune=generic -O3 -ffast-math -mavx2 -mfma -pipe" \
            --extra-backend-cmake-arg=onnxruntime:CMAKE_CXX_FLAGS="-march=core-avx2 -mtune=generic -O3 -ffast-math -mavx2 -mfma -pipe" \
            --override-backend-cmake-arg=tensorflow:TRITON_ENABLE_GPU=OFF \
            --override-backend-cmake-arg=tensorflow:TRITON_ENABLE_STATS=OFF \
            --override-backend-cmake-arg=tensorflow:TRITON_BACKEND_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=tensorflow:TRITON_CORE_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=tensorflow:TRITON_COMMON_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=tensorflow:TRITON_TENSORFLOW_DOCKER_IMAGE=tensorflow/tensorflow:2.18.0 \
            --extra-backend-cmake-arg=tensorflow:TRITON_TENSORFLOW_INSTALL_EXTRA_DEPS=ON \
            --extra-backend-cmake-arg=tensorflow:CMAKE_C_FLAGS="-march=core-avx2 -mtune=generic -O3 -mavx2 -mfma" \
            --extra-backend-cmake-arg=tensorflow:CMAKE_CXX_FLAGS="-march=core-avx2 -mtune=generic -O3 -mavx2 -mfma" \
            --override-backend-cmake-arg=python:TRITON_ENABLE_GPU=OFF \
            --override-backend-cmake-arg=python:TRITON_ENABLE_STATS=OFF \
            --override-backend-cmake-arg=python:TRITON_BACKEND_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=python:TRITON_CORE_REPO_TAG=r25.02 \
            --override-backend-cmake-arg=python:TRITON_COMMON_REPO_TAG=r25.02
          docker images
      - name: Log into registry
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - name: Push image
        run: |
          IMAGE_ID=ghcr.io/${{ github.repository_owner }}/$IMAGE_NAME
          VERSION=$IMAGE_TAG_PREFIX.${{ github.run_number }}
          docker tag tritonserver:latest $IMAGE_ID:$VERSION
          docker push $IMAGE_ID:$VERSION
